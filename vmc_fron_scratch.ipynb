{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always shorten netket as nk\n",
    "import netket as nk\n",
    "\n",
    "# Define a 1d chain\n",
    "L = 4\n",
    "g = nk.graph.Hypercube(length=L, n_dim=2, pbc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g.n_nodes: 16\n",
      "g.nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "g.n_edges: 32\n",
      "g.edges: [(3, 7), (12, 13), (8, 9), (8, 12), (2, 14), (13, 14), (4, 5), (5, 6), (4, 8), (12, 15), (5, 9), (14, 15), (3, 15), (8, 11), (0, 1), (9, 10), (1, 2), (0, 4), (9, 13), (10, 11), (1, 5), (10, 14), (6, 7), (6, 10), (4, 7), (0, 3), (0, 12), (2, 3), (1, 13), (2, 6), (11, 15), (7, 11)]\n"
     ]
    }
   ],
   "source": [
    "# The number of sites (called nodes):\n",
    "print(\"g.n_nodes:\", g.n_nodes)\n",
    "# You can iterate through the nodes:\n",
    "print(\"g.nodes:\", [node for node in g.nodes()])\n",
    "# You can check the number of edges:\n",
    "print(\"g.n_edges:\", g.n_edges)\n",
    "# You can iterate through the edges, which are stored as a 2-tuple with the start and end node:\n",
    "print(\"g.edges:\", g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hilbert space based on this graph\n",
    "# We impose to have a fixed total magnetization of zero \n",
    "hi = nk.hilbert.Spin(s=1/2, N=g.n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_1 = nk.operator.spin.sigmax(hi, 1)\n",
    "sy_2 = nk.operator.spin.sigmay(hi, 2)\n",
    "sz_2 = nk.operator.spin.sigmaz(hi, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates an empty operator (or zero) to which you can add others.\n",
    "hamiltonian = nk.operator.LocalOperator(hi)\n",
    "\n",
    "# now add all terms acting on single sites\n",
    "for site in g.nodes(): # every node (take the list of nodes from the graph object g that we constructed before)\n",
    "    hamiltonian += - nk.operator.spin.sigmax(hi, site)\n",
    "\n",
    "    # now add all terms acting on multiple sites\n",
    "for (i,j) in g.edges(): # every edge (take the list of edges from the graph object)\n",
    "    hamiltonian = hamiltonian + nk.operator.spin.sigmaz(hi, i) * nk.operator.spin.sigmaz(hi, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonian_jax = hamiltonian.to_pauli_strings().to_jax_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "hamiltonian_correct = nk.operator.Ising(hi, g, h=1.0, J=1.0)\n",
    "assert np.sum(np.abs(hamiltonian_correct.to_sparse() - hamiltonian.to_sparse())**2) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-34.01059755084627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy \n",
    "e_gs, psi_gs = scipy.sparse.linalg.eigsh(hamiltonian.to_sparse(), k=1, which='SA')\n",
    "e_gs = e_gs[0]\n",
    "psi_gs = psi_gs.reshape(-1)\n",
    "e_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all is good, this cell should validate\n",
    "assert e_gs.shape == ()\n",
    "assert psi_gs.shape == (hi.n_states, )\n",
    "assert -34.01060 < e_gs < -34.01059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# numerical operations in the model should always use jax.numpy \n",
    "# instead of numpy because jax supports computing derivatives. \n",
    "# If you want to better understand the difference between the two, check\n",
    "# https://flax.readthedocs.io/en/latest/notebooks/jax_for_the_impatient.html\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Flax is a framework to define models using jax\n",
    "import flax\n",
    "# we refer to `flax.linen` as `nn`. It's a repository of \n",
    "# layers, initializers and nonlinear functions.\n",
    "import flax.linen as nn\n",
    "\n",
    "# A Flax model must be a class subclassing `nn.Module`\n",
    "class MF(nn.Module):\n",
    "    \n",
    "    # The most compact way to define the model is this.\n",
    "    # The __call__(self, x) function should take as \n",
    "    # input a batch of states x.shape = (n_samples, N)\n",
    "    # and should return a vector of n_samples log-amplitudes\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # A tensor of variational parameters is defined by calling\n",
    "        # the method `self.param` where the arguments will be:\n",
    "        # - arbitrary name used to refer to this set of parameters\n",
    "        # - an initializer used to provide the initial values. \n",
    "        # - The shape of the tensor\n",
    "        # - The dtype of the tensor.\n",
    "        lam = self.param(\n",
    "            \"lambda\", nn.initializers.normal(), (1,), float\n",
    "        )\n",
    "        \n",
    "        # compute the probabilities\n",
    "        p = nn.log_sigmoid(lam*x)\n",
    "\n",
    "        # sum the output\n",
    "        return 0.5 * jnp.sum(p, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model\n",
    "model = MF()\n",
    "\n",
    "# pick a RNG key to initialise the random parameters\n",
    "key = jax.random.key(0)\n",
    "\n",
    "# initialise the weights\n",
    "parameters = model.init(key, np.random.rand(hi.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply_by_10:              {'a': 10, 'b': 20}\n",
      "multiply_by_10, with lambda: {'a': 10, 'b': 20}\n",
      "add dict1 and 2          : {'a': 2, 'b': 0}\n",
      "subtract dict1 and 2        : {'a': 0, 'b': 4}\n",
      "subtract dict1 and 2, lambda: {'a': 0, 'b': 4}\n"
     ]
    }
   ],
   "source": [
    "dict1 = {'a':1, 'b':2}\n",
    "dict2 = {'a':1, 'b':-2}\n",
    "\n",
    "def multiply_by_10(x):\n",
    "    return 10*x\n",
    "\n",
    "print(\"multiply_by_10:             \", jax.tree.map(multiply_by_10,  dict1))\n",
    "# this can also be done by defining the function as a lambda function, which is more compact\n",
    "print(\"multiply_by_10, with lambda:\", jax.tree.map(lambda x: 10*x,  dict1))\n",
    "\n",
    "def add(x,y):\n",
    "    return x+y\n",
    "print(\"add dict1 and 2          :\", jax.tree.map(add, dict1, dict2))\n",
    "\n",
    "\n",
    "def sub(x,y):\n",
    "    return x-y\n",
    "print(\"subtract dict1 and 2        :\", jax.tree.map(sub, dict1, dict2))\n",
    "print(\"subtract dict1 and 2, lambda:\", jax.tree.map(lambda x,y:x-y, dict1, dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# generate 4 random inputs\n",
    "inputs = hi.random_state(jax.random.key(1), (4,))\n",
    "\n",
    "log_psi = model.apply(parameters, inputs)\n",
    "# notice that logpsi has shape (4,) because we fed it 4 random configurations.\n",
    "print(log_psi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-5.55575789, -5.55575789, -5.54559091, -5.54559091], dtype=float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def to_array(model, parameters): # -> Array:\n",
    "    # begin by generating all configurations in the hilbert space.\n",
    "    # all_States returns a batch of configurations that is (hi.n_states, N) large.\n",
    "    all_configurations = hi.all_states()\n",
    "\n",
    "    # now evaluate the model, and convert to a normalised wavefunction.\n",
    "    log_psi = model.apply(parameters, all_configurations)\n",
    "    psi = jnp.exp(log_psi)\n",
    "    psi = psi / jnp.linalg.norm(psi)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you did it correctly, this test should pass\n",
    "\n",
    "assert to_array(model, parameters).shape == (hi.n_states, )\n",
    "assert np.all(to_array(model, parameters) > 0)\n",
    "np.testing.assert_allclose(np.linalg.norm(to_array(model, parameters)), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.0042355 , 0.00419265, 0.00419265, ..., 0.0036364 , 0.0036364 ,\n",
       "       0.00359962], dtype=float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# static_argnames must be used to tag any argument that is not a pytree or an array. In this case, the model.\n",
    "to_array_jit = jax.jit(to_array, static_argnames=\"model\")\n",
    "\n",
    "# run it once to compile it, before benchmarking\n",
    "to_array_jit(model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "def compute_energy(model, parameters, hamiltonian):\n",
    "    psi_gs = to_array(model, parameters)\n",
    "    return psi_gs.conj().T @ (hamiltonian @ psi_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all is good, this should not error\n",
    "assert compute_energy(model, parameters, hamiltonian.to_sparse()).shape == ()\n",
    "assert compute_energy(model, parameters, hamiltonian.to_sparse()) < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and like before, we can jit-compile it!\n",
    "compute_energy_jit = jax.jit(compute_energy, static_argnames=\"model\")\n",
    "\n",
    "# and we precompute the sparse-hamiltonian to avoid the overhead of re-computing them all the time\n",
    "hamiltonian_sparse = hamiltonian.to_sparse()\n",
    "hamiltonian_jax_sparse = hamiltonian_jax.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 346 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "20.1 ms ± 540 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_energy(model, parameters, hamiltonian_sparse)\n",
    "%timeit compute_energy_jit(model, parameters, hamiltonian_jax_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# we use partial to directly jit this function. Jitting the top-most will jit everything inside it as well.\n",
    "@partial(jax.jit, static_argnames='model')\n",
    "def compute_energy_and_gradient(model, parameters, hamiltonian_sparse):\n",
    "    grad_fun = jax.value_and_grad(compute_energy, argnums=1)\n",
    "    return grad_fun(model, parameters, hamiltonian_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'lambda': Array([-0.40662741], dtype=float64)}}\n"
     ]
    }
   ],
   "source": [
    "energy, gradient = compute_energy_and_gradient(model, parameters, hamiltonian_jax_sparse)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/qj/clm7jsc121ldh0pcf5z2czkc0000gp/T/ipykernel_6653/3802880836.py:20: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  parameters = jax.tree_map(lambda x, g: x - 0.01 * g, parameters, gradient)\n",
      "  1%|          | 1/100 [00:00<00:12,  7.78it/s]/var/folders/qj/clm7jsc121ldh0pcf5z2czkc0000gp/T/ipykernel_6653/3802880836.py:20: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  parameters = jax.tree_map(lambda x, g: x - 0.01 * g, parameters, gradient)\n",
      "100%|██████████| 100/100 [00:03<00:00, 25.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# initialise \n",
    "model = MF()\n",
    "parameters = model.init(jax.random.key(0), np.ones((hi.size, )))\n",
    "iterations = 100\n",
    "\n",
    "# logging: you can (if you want) use netket loggers to avoid writing a lot of boilerplate...\n",
    "# they accumulate data you throw at them\n",
    "logger = nk.logging.RuntimeLog()\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    # compute energy and gradient\n",
    "    energy, gradient = compute_energy_and_gradient(model, parameters, hamiltonian_jax_sparse)\n",
    "    \n",
    "    # update parameters. Try using a learning rate of 0.01\n",
    "    # to update the parameters, which are stored as a dictionary (or pytree)\n",
    "    # you can use jax.tree.map as shown above.\n",
    "    #...\n",
    "    parameters = jax.tree_map(lambda x, g: x - 0.01 * g, parameters, gradient)\n",
    "    \n",
    "    # log energy: the logger takes a step argument and a dictionary of variables to be logged\n",
    "    logger(step=i, item={'Energy' : energy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13f7f71a0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to plot the data, access it!\n",
    "plt.plot(logger.data['Energy']['iters'], logger.data['Energy']['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Flax model must be a class subclassing `nn.Module`\n",
    "class Jastrow(nn.Module):\n",
    "    \n",
    "    # The most compact way to define the model is this.\n",
    "    # The __call__(self, input_x) function should take as \n",
    "    # input a batch of states input_x.shape = (n_samples, N)\n",
    "    # and should return a vector of n_samples log-amplitudes\n",
    "    @nn.compact\n",
    "    def __call__(self, input_x):\n",
    "        \n",
    "        n_sites = input_x.shape[-1]\n",
    "        \n",
    "        # A tensor of variational parameters is defined by calling\n",
    "        # the method `self.param` where the arguments will be:\n",
    "        # - arbitrary name used to refer to this set of parameters\n",
    "        # - an initializer used to provide the initial values. \n",
    "        # - The shape of the tensor\n",
    "        # - The dtype of the tensor.\n",
    "        # Define the two variational parameters J1 and J2\n",
    "        J = self.param(\n",
    "            \"J\", nn.initializers.normal(), (n_sites,n_sites), float\n",
    "        )\n",
    "        # ensure same data types\n",
    "        dtype = jax.numpy.promote_types(J.dtype, input_x.dtype)\n",
    "        J = J.astype(dtype)\n",
    "        input_x = input_x.astype(dtype)\n",
    "        \n",
    "        # note that J_ij is not symmetric. So we symmetrize it by hand\n",
    "        J_symm = J.T + J\n",
    "        \n",
    "        # TODO compute the result \n",
    "        res = jnp.einsum(\"...i, ij, ...j\", input_x, J_symm, input_x)# use vectorised operations. Make sure they work with arbitrary shapes of dimensions.\n",
    "        # look into jnp.einsum.\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the code above is correct, this should run\n",
    "model_jastrow = Jastrow()\n",
    "\n",
    "one_sample = hi.random_state(jax.random.key(0))\n",
    "batch_samples = hi.random_state(jax.random.key(0), (5,))\n",
    "multibatch_samples = hi.random_state(jax.random.key(0), (5,4,))\n",
    "\n",
    "parameters_jastrow = model_jastrow.init(jax.random.key(0), one_sample)\n",
    "assert parameters_jastrow['params']['J'].shape == (hi.size, hi.size)\n",
    "assert model_jastrow.apply(parameters_jastrow, one_sample).shape == ()\n",
    "assert model_jastrow.apply(parameters_jastrow, batch_samples).shape == batch_samples.shape[:-1]\n",
    "assert model_jastrow.apply(parameters_jastrow, multibatch_samples).shape == multibatch_samples.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = nk.sampler.MetropolisSampler(\n",
    "                        hi,                            # the hilbert space to be sampled\n",
    "                        nk.sampler.rules.LocalRule(),  # the transition rule\n",
    "                        n_chains = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "sampler_state = sampler.init_state(model, parameters, seed=1)\n",
    "sampler_state = sampler.reset(model, parameters, sampler_state)\n",
    "samples, sampler_state = sampler.sample(model, parameters, state=sampler_state, chain_length=100)\n",
    "\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given sigma\n",
    "sigma = hi.random_state(jax.random.key(1))\n",
    "\n",
    "eta, H_sigmaeta = hamiltonian_jax.get_conn_padded(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(17, 16)\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "# so for 1 sample sigma\n",
    "print(sigma.shape)\n",
    "\n",
    "# we have 17 connected samples eta, each composed by 16 spins\n",
    "print(eta.shape)\n",
    "# and 17 matrix elements\n",
    "print(H_sigmaeta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 16)\n",
      "(4, 5, 17, 16)\n",
      "(4, 5, 17)\n"
     ]
    }
   ],
   "source": [
    "# given sigma\n",
    "sigma = hi.random_state(jax.random.key(1), (4,5))\n",
    "\n",
    "eta, H_sigmaeta = hamiltonian_jax.get_conn_padded(sigma)\n",
    "\n",
    "# so for each of the (4,5) samples sigma each of 16 spins\n",
    "print(sigma.shape)\n",
    "\n",
    "# we have 17 connected samples eta, each composed by 16 spins, in a tensor of shape (4,5,17,16)\n",
    "print(eta.shape)\n",
    "# and 17 matrix elements\n",
    "print(H_sigmaeta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_energies(model, parameters, hamiltonian_jax, sigma):\n",
    "    eta, H_sigmaeta = hamiltonian_jax.get_conn_padded(sigma)\n",
    "    \n",
    "    logpsi_sigma = model.apply(parameters, sigma)\n",
    "    logpsi_eta = model.apply(parameters, eta)\n",
    "\n",
    "    logpsi_sigma = jnp.expand_dims(logpsi_sigma, -1)\n",
    "\n",
    "    # to match their dimensions and broadcast, jnp.expand_dims(logpsi_sigma, -1) might help\n",
    "    res = jnp.sum(H_sigmaeta * jnp.exp(logpsi_eta - logpsi_sigma), axis=(-1))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wrote it correctly, you should get to work the following tests\n",
    "assert compute_local_energies(model, parameters, hamiltonian_jax, samples[0]).shape == samples.shape[1:-1]\n",
    "assert compute_local_energies(model, parameters, hamiltonian_jax, samples).shape == samples.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-20., -16., -12., -20., -12.],\n",
       "       [-16., -12., -16., -16., -12.],\n",
       "       [-16., -16., -12., -20., -24.],\n",
       "       [-16., -20., -24., -16., -12.]], dtype=float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and if you did not do crazy things, this should also jit compile\n",
    "jax.jit(compute_local_energies, static_argnames='model')(model, parameters, hamiltonian_jax, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames='model')\n",
    "def estimate_energy(model, parameters, hamiltonian_jax, sigma):\n",
    "    E_loc = compute_local_energies(model, parameters, hamiltonian_jax, sigma)\n",
    "    \n",
    "    E_average = jnp.mean(E_loc)\n",
    "    E_variance = jnp.var(E_loc)\n",
    "    E_error = jnp.sqrt(E_variance / E_loc.size)\n",
    "    \n",
    "    # we return a netket Stats object that wraps all statistical information related to this mean value.\n",
    "    return nk.stats.Stats(mean=E_average, error_of_mean=E_error, variance=E_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.85 ± 0.12 [σ²=30.97]\n"
     ]
    }
   ],
   "source": [
    "# this should run correctly\n",
    "isinstance(estimate_energy(model, parameters, hamiltonian_jax, samples), nk.stats.Stats)\n",
    "print(estimate_energy(model, parameters, hamiltonian_jax, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact:  -15.999999999999408\n",
      "Estimate:  -16.007 ± 0.018 [σ²=32.055]\n"
     ]
    }
   ],
   "source": [
    "samples_many, sampler_state = sampler.sample(model, parameters, state=sampler_state, chain_length=5000)\n",
    "\n",
    "print(\"exact: \", compute_energy(model, parameters, hamiltonian_jax))\n",
    "print(\"Estimate: \", estimate_energy(model, parameters, hamiltonian_jax, samples_many))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
