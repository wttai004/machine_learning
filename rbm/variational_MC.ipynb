{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import sqrt\n",
    "from model import Model\n",
    "from rbm import RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbm_operator import Operator, Sx_, Sz_, SzSz_, set_h_Hamiltonian, set_J1_Hamiltonian, set_J2_Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple attempt to implement a variational quantum state calculation \n",
    "\n",
    "As an example, we start with a very simple J1/J2 Heisenberg spin chain\n",
    "\n",
    "We define a class \"model\" that contains a Hamiltonian and a rule for generating spins according to the MSMS algorithm.\n",
    "\n",
    "We have something to obtain the wavefunction amplitude $\\psi_\\theta(s)$ from the spin configuration $s$ that depends on some amplitude $\\theta$\n",
    "\n",
    "From  $\\psi_\\theta(s)$ for the given spin configuration, we can produce an estimate of the energy of the variational ground state.\n",
    "\n",
    "Then we can perform a stochastic gradient descent based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the operators are defined as \n",
    "$$S\\cdot S = S_x \\cdot S_x + S_y \\cdot S_y + S_z \\cdot S_z = \\frac{1}{2} (S_+ \\cdot S_- + S_- \\cdot S_+) + S_z \\cdot S_z$$\n",
    "\n",
    "where $S_z = \\frac{\\hbar}{2} \\begin{pmatrix} 1 & 0 \\\\ 0  & -1 \\end{pmatrix}$, $S_+ = \\hbar \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = S_x + S_y$, $S_- = \\hbar \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = S_x - S_y$. A singlet state has energy $-3J/4$ and a triplet state has energy $J/4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sanity check has been migrated to operator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying that the Hamiltonian evaluated onto spins give sensible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating random spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Model(4, 4)\n",
    "test.get_random_spins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the RBM class\n",
    "\n",
    "After having a class of spin and Hamiltonian, consider a wavefunction object, take takes a spin and returns a number. The variational quantum state is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) = \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\n",
    "\\end{align*}\n",
    "\n",
    "Here the free parameters of the models are $a_i, b_, W_{ij}$ and $h_1, \\dots, h_M$ represents auxilliary spin variables in the network. The internal spins can be explicited traced out to read\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi(S;W) = e^{\\sum_j a_j \\sigma^z_j} \\times \\Pi_{i=1}^M F_i(S)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "F_i(S) = 2\\cosh\\left[ b_i + \\sum_J W_{ij} \\sigma^z_j\\right] =  2\\cosh\\theta_i\n",
    "\\end{align*}\n",
    "\n",
    "The object would be an NN (most basic example includes the Carleo RBM, which actually has an analytical form) \n",
    "\n",
    "I need a function to compute the variational energy. A function to give gradient. And a function to do the gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    \"\"\"\n",
    "    A reduced Boltzmann machine that implements the spin wavefunction based on the model class\n",
    "    \"\"\"\n",
    "    def __init__(self, model) -> None:\n",
    "        self.model = model\n",
    "        self.L1 = model.L1\n",
    "        self.L2 = model.L2\n",
    "        self.M = 3*int(self.L1*self.L2/2)\n",
    "\n",
    "        self.a = np.random.random(self.L1*self.L2)-0.5#np.ones(self.L1 * self.L2)\n",
    "        self.b = np.random.random(self.M)-0.5#np.zeros(self.M)\n",
    "        self.M = np.random.random((self.M, self.L1 * self.L2))-0.5#np.ones((self.M, self.L1 * self.L2))\n",
    "\n",
    "    def theta(self, spin)->float:\n",
    "        \"\"\"\n",
    "        Helper function: evaluates the product bj + Wij sigma i\n",
    "        \"\"\"\n",
    "        assert spin.shape == (self.L1, self.L2, 2), f\"Invalid spin shape {spin.shape}\"\n",
    "        projected_spin = self.model.project_spin(spin)\n",
    "        return self.b + np.dot(self.M, projected_spin)\n",
    "\n",
    "    def evaluate(self, spin) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the wavefunction for a given spin configuration\n",
    "        \"\"\"\n",
    "        assert spin.shape == (self.L1, self.L2, 2), f\"Invalid spin shape {spin.shape}\"\n",
    "        projected_spin = self.model.project_spin(spin)\n",
    "        #print(self.M, projected_spin, np.prod(2 * np.cosh(self.b + np.dot(self.M, projected_spin))))\n",
    "        return np.exp(np.dot(self.a, projected_spin)) * np.prod(2 * np.cosh(self.b + np.dot(self.M, projected_spin)))\n",
    "\n",
    "    def evaluate_dummy(self, spin) -> float:\n",
    "        assert spin.shape == (self.L1, self.L2, 2), f\"Invalid spin shape {spin.shape}\"\n",
    "        return 20 if (spin[0, 0, 0] == 1 and spin[0,1,0] == 1) else 1\n",
    "\n",
    "    def metropolis_step(self, spin):\n",
    "        \"\"\"\n",
    "        Perform a single Metropolis step\n",
    "        \"\"\"\n",
    "        spin2 = self.model.flip_random_spin(spin)\n",
    "        #print(self.evaluate(spin2),self.evaluate(spin))\n",
    "        #p = min(1, (self.evaluate(spin2) / self.evaluate(spin))**2)\n",
    "        p = min(1, (self.evaluate_dummy(spin2) / self.evaluate_dummy(spin)))\n",
    "        if random.random() < p:\n",
    "            return spin2\n",
    "        return spin\n",
    "    \n",
    "    def create_batch(self, N, burn_in = 100, skip = 10):\n",
    "        \"\"\"\n",
    "        Create a batch of N spins\n",
    "        \"\"\"\n",
    "        assert type(N) == int and N >= 1\n",
    "        result_array = np.zeros((N, self.L1, self.L2, 2), dtype = int)\n",
    "        current_spins = self.model.get_random_spins()\n",
    "        for _ in range(burn_in):\n",
    "            current_spins = self.metropolis_step(current_spins)\n",
    "        #print(result_array.shape, current_spins.shape, self.L1, self.L2)\n",
    "        result_array[0] = current_spins\n",
    "        for i in range(1, N*skip):\n",
    "            current_spins = self.metropolis_step(current_spins)\n",
    "            if i % skip == 0:\n",
    "                result_array[i//skip] = current_spins\n",
    "        return result_array\n",
    "\n",
    "    def expectation_value(self, operator, spin, burn_in = 100, skip = 10):\n",
    "        \"\"\"\n",
    "        Evaluate the expectation value of an operator for a given spin configuration\n",
    "        \"\"\"\n",
    "        assert spin.shape == (self.L1, self.L2, 2), f\"Invalid spin shape {spin.shape}\"\n",
    "        spin1 = spin\n",
    "        spin2s = self.model.generate_local_spins(spin1, change = 2)#[self.model.get_random_spins() for _ in range(N)]#self.create_batch(N, burn_in = burn_in, skip = skip)\n",
    "        result = 0\n",
    "        for spin2 in spin2s:\n",
    "            #print(spin1, spin2)\n",
    "            #print(spin1, spin2, operator.vdot(spin1, spin2), self.evaluate_dummy(spin2), self.evaluate_dummy(spin1))\n",
    "            result += operator.vdot(spin1, spin2) * self.evaluate_dummy(spin2) / self.evaluate_dummy(spin1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators and derivatives: \n",
    "\n",
    "Noting that an operator dcdan be approximated by its local value\n",
    "\n",
    "\\begin{align*}\n",
    "O_{loc}(s) = \\sum_{s, s'}  \\left< s\\middle| O \\middle| s' \\right>\\frac{\\left<s' \\middle| \\Phi_\\theta\\right>}{\\left<s \\middle| \\Phi_\\theta\\right>}\n",
    "\\end{align*}\n",
    "\n",
    "and an operator's expectation value can be reasonably approximated by \n",
    "\n",
    "\\begin{align*}\n",
    "\\left<O \\right> = \\sum_{s} P(s) O_{loc}(s) \\approx \\frac{1}{M} \\sum_{s_i} O_{loc}(s_i)\n",
    "\\end{align*}\n",
    "\n",
    "Now consider the energy minimization. Let $O_p(s) = \\frac{\\partial}{\\partial \\theta_p} \\log \\left<s\\middle|\\Psi_\\theta\\right> = \\left<s\\middle|O_p \\middle| s\\right> $,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E(\\theta)}{\\partial \\theta_p} &= 2 \\Re \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) O^*(\\mathbf{s}) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle O^*(\\mathbf{s}) \\right\\rangle \\right] \\\\\n",
    "&= 2 \\Re \\left[ \\left\\langle (E_{\\text{loc}}(\\mathbf{s}) - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle) O^*(\\mathbf{s}) \\right\\rangle \\right]\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: expectation value of operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-site operators (SzSz only, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <SzSz|ud__|SzSz> is (-0.25+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|dd__|Sz> is (0.25+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.20500000000000002+0j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <SzSz|ud__|SzSz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[0, 1], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|dd__|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-site operator (Sz makes sense. Unsure if Sx does, but I'll sweep it under the rug for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (0.5+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is (-0.5+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is 0j)\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (-1+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.02+0j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.05+0j))\n"
     ]
    }
   ],
   "source": [
    "operator = Operator(model)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        operator += Sz_(i, j, model)\n",
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(operator, batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sx|u___|Sx> is (0.5+0j) with standard deviation 0.0\n",
      "The average expectation  <Sx|d___|Sx> is (0.5+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.5+0j))\n"
     ]
    }
   ],
   "source": [
    "#NB: This assumes that the spin is up for probability 2/3 and down for probabilty 1/3\n",
    "#If you set them to be the same the spin expectation is 1/2, which checks out for |up>+|dn>\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sx|u___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sx|d___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(100) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sx_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sy|u___|Sy> is -0.5j with standard deviation 0.0\n",
      "The average expectation  <Sy|d___|Sy> is -0.5j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is 0.015j)\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sy|u___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sy|d___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry of the RBM.\n",
    "\n",
    "Consider a translation operator working as $\\sigma_j(k) = T_k \\sigma_j$. An obvious requirement for translation symmetry is that $\\Psi_\\theta(\\sigma) = \\Psi_\\theta(T_s\\sigma)$, and an obvious way to implement this is to just artificially sum over contributions on the output $\\sum_i \\Psi_\\theta(T_{s_i}\\sigma)$, but this won't improve the efficiency of the algorithm.\n",
    "\n",
    "A more tractable wa is to use convolutions. Before we have RBM as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) &= \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, we can rewrite it as below, where $f = 1, \\alpha_s$ is a number of feature maps, and in particular $W_{j}^{(f)} $ has $\\alpha_s \\times N$ elements. Note that because the spins are all summed over all translations this is translation invariant.\n",
    "\n",
    "\\begin{equation}\n",
    "\\Psi_{\\alpha}(\\mathbf{S}; \\mathbf{W}) = \\sum_{h_{i,s}} \\exp \\left[ \\sum_{f}^{a} \\left( a^{(s)} \\sum_{s}^{S} \\sum_{j}^{N} \\tilde{\\sigma}_{j}^{z}(s) + b_{f}^{(s)} h_{f,s} + \\sum_{s}^{S} \\sum_{j}^{N} h_{f,s} W_{j}^{(f)} \\tilde{\\sigma}_{j}^{z}(s) \\right) \\right],\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The irreversible trash heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self, model: Model) -> None:\n",
    "        self.model = model\n",
    "        self.L1 = model.L1\n",
    "        self.L2 = model.L2\n",
    "        self.onesiteoperators = []#np.zeros((self.L1, self.L2, 2, 2), dtype = complex)\n",
    "        self.twositeoperators = []#np.zeros((self.L1, self.L2, self.L1, self.L2, 2, 2, 2, 2), dtype = complex)\n",
    "        # #adding the identity operators\n",
    "        # for i in range(self.L1):\n",
    "        #     for j in range(self.L2):\n",
    "        #         self.onesiteoperators[i, j, 0, 0] = 1  \n",
    "        #         self.onesiteoperators[i, j, 1, 1] = 1\n",
    "        # for i1 in range(self.L1):\n",
    "        #     for j1 in range(self.L2):\n",
    "        #         for i2 in range(self.L1):\n",
    "        #             for j2 in range(self.L2):\n",
    "        #                 self.twositeoperators[i1, j1, i2, j2, 0, 0, 0, 0] = 1  \n",
    "        #                 self.twositeoperators[i1, j1, i2, j2, 0, 1, 0, 1] = 1  \n",
    "        #                 self.twositeoperators[i1, j1, i2, j2, 1, 1, 1, 1] = 1\n",
    "        #                 self.twositeoperators[i1, j1, i2, j2, 1, 0, 1, 0] = 1  \n",
    "    def generate_identity(self):\n",
    "        result = np.zeros((self.L1, self.L2, 2, 2), dtype = complex)\n",
    "        #adding the identity operators\n",
    "        for i in range(self.L1):\n",
    "            for j in range(self.L2):\n",
    "                result[i, j, 0, 0] = 1  \n",
    "                result[i, j, 1, 1] = 1\n",
    "        return result\n",
    "\n",
    "    def add_Sx(self, i, j):\n",
    "        self.onesiteoperators[i, j, 0, 1] = 1/2\n",
    "        self.onesiteoperators[i, j, 1, 0] = 1/2\n",
    "    \n",
    "    def add_Sy(self, i, j):\n",
    "        self.onesiteoperators[i, j, 0, 1] = -1j * 1/2\n",
    "        self.onesiteoperators[i, j, 1, 0] = 1j * 1/2\n",
    "\n",
    "    def add_Sz(self, i, j):\n",
    "        operator = self.generate_identity()\n",
    "        operator[i, j, 0, 0] = 1/2\n",
    "        operator[i, j, 1, 1] = -1/2\n",
    "        self.onesiteoperators.append(operator)\n",
    "\n",
    "    def add_SzSz(self, i1, j1, i2, j2):\n",
    "        self.twositeoperators[i1, j1, i2, j2, 0, 0, 0, 0] += 1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 0, 1, 0, 1] += -1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 1, 0, 1, 0] += -1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 1, 1, 1, 1] += 1/4 \n",
    "\n",
    "    def add_SdotS_interaction(self, i1, j1, i2, j2):\n",
    "        \"\"\" \n",
    "        Add the S(r1).S(r2) interaction between spins at r1 and r2, with strength J\n",
    "\n",
    "        The Hamiltonian represents the entries 1/2(S+(r1).S-(r2) + S-(r1).S+(r2)) + Sz(r1).Sz(r2)\n",
    "        \"\"\"\n",
    "        self.twositeoperators[i1, j1, i2, j2, 0, 0, 0, 0] += 1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 0, 1, 0, 1] += -1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 0, 1, 1, 0] += 1/2\n",
    "        self.twositeoperators[i1, j1, i2, j2, 1, 0, 1, 0] += -1/4 \n",
    "        self.twositeoperators[i1, j1, i2, j2, 1, 0, 0, 1] += 1/2\n",
    "        self.twositeoperators[i1, j1, i2, j2, 1, 1, 1, 1] += 1/4 \n",
    "\n",
    "    def __mul__(self, number):\n",
    "        #Multiply the operator by a scalar\n",
    "        newObject = Operator(self.model)\n",
    "        newObject.onesiteoperators = self.onesiteoperators * number\n",
    "        newObject.twositeoperators = self.twositeoperators * number\n",
    "        return newObject\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        #Add two operators\n",
    "        assert self.L1 == other.L1 and self.L2 == other.L2, \"Cannot add operators of different sizes\"\n",
    "        newObject = Operator(self.model)\n",
    "        newObject.onesiteoperators = self.onesiteoperators + other.onesiteoperators\n",
    "        newObject.twositeoperators = self.twositeoperators + other.twositeoperators\n",
    "        return newObject\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        #Subtract two operators\n",
    "        assert self.L1 == other.L1 and self.L2 == other.L2, \"Cannot subtract operators of different sizes\"\n",
    "        newObject = Operator(self.model)\n",
    "        newObject.onesiteoperators = self.onesiteoperators - other.onesiteoperators\n",
    "        newObject.onesiteoperators = self.twositeoperators - other.twositeoperators\n",
    "        return newObject\n",
    "    \n",
    "    # def dot(self, spin):\n",
    "    #     assert spin.dtype == int, f\"Hdot cannot handle spins of type {spin.dtype}. Please convert this to int\"\n",
    "    #     assert np.all(np.sum(spin, axis = -1) == 1), \"spin is not properly normalized\"\n",
    "    #     onesiteresult = 0\n",
    "    #     for operator in self.onesiteoperators:\n",
    "    #         onesiteresult += np.einsum(\"ijkl, ijk->ijl\", operator, spin)\n",
    "    #     twositeresult = 0\n",
    "    #     temp = np.copy(spin)\n",
    "    #     for operator_combo in self.twositeoperators:\n",
    "    #         for operator in operator_combo:\n",
    "    #             temp = np.einsum(\"ijkl, ijk->ijl\", operator, temp)\n",
    "    #         twositeresult += temp\n",
    "    #     return onesiteresult + twositeresult\n",
    "    def vdot(self, spin1, spin2):\n",
    "        #return the vector product between the operator and the spin\n",
    "        assert spin1.dtype == int and spin2.dtype == int, f\"Hdot cannot handle spins of type {spin1.dtype}. Please convert this to int\"\n",
    "        assert np.all(np.sum(spin1, axis = -1) == 1), \"spin1 is not properly normalized\"\n",
    "        assert np.all(np.sum(spin2, axis = -1) == 1), f\"spin2 is not properly normalized for {spin2}\"\n",
    "        onesiteresult = self.model.vdot(spin1, np.einsum(\"ijkl, ijk->ijl\", self.onesiteoperators, spin2))\n",
    "        twositeresult = 0\n",
    "        return onesiteresult + twositeresult\n",
    "        #return np.einsum('ijk,ijl,ijkl->', spin1, spin2, self.onesiteoperators) +  np.einsum('ija,klb,ijc,kld,ijklabcd->', spin1, spin1, spin2, spin2, self.twositeoperators)\n",
    "        \n",
    "def Sx_(i, j, model):\n",
    "    \"\"\"\n",
    "    Create the Sx operator at site i,j\n",
    "    \"\"\"\n",
    "    result = Operator(model)\n",
    "    result.add_Sx(i, j)\n",
    "    return result\n",
    "\n",
    "def Sy_(i, j, model):\n",
    "    \"\"\"\n",
    "    Create the Sy operator at site i,j\n",
    "    \"\"\"\n",
    "    result = Operator(model)\n",
    "    result.add_Sy(i, j)\n",
    "    return result\n",
    "\n",
    "def Sz_(i, j, model):\n",
    "    \"\"\"\n",
    "    Create the Sz operator at site i,j\n",
    "    \"\"\"\n",
    "    result = Operator(model)\n",
    "    result.add_Sz(i, j)\n",
    "    return result\n",
    "\n",
    "def SzSz_(i1, j1, i2, j2, model):\n",
    "    \"\"\"\n",
    "    Create the SzSz operator at sites i1,j1 and i2,j2\n",
    "    \"\"\"\n",
    "    result = Operator(model)\n",
    "    result.add_SzSz(i1, j1, i2, j2)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
