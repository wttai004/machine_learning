{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import tanh\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import sqrt\n",
    "from model import Model\n",
    "from rbm import RBM\n",
    "from rbm_operator import Operator, Sx_, Sy_, Sz_, SzSz_, set_h_Hamiltonian, set_J1_Hamiltonian, set_J2_Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple attempt to implement a variational quantum state calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the operators are defined as \n",
    "$$S\\cdot S = S_x \\cdot S_x + S_y \\cdot S_y + S_z \\cdot S_z = \\frac{1}{2} (S_+ \\cdot S_- + S_- \\cdot S_+) + S_z \\cdot S_z$$\n",
    "\n",
    "where $S_z = \\frac{\\hbar}{2} \\begin{pmatrix} 1 & 0 \\\\ 0  & -1 \\end{pmatrix}$, $S_+ = \\hbar \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = S_x + S_y$, $S_- = \\hbar \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = S_x - S_y$. A singlet state has energy $-3J/4$ and a triplet state has energy $J/4$\n",
    "\n",
    "As an example, we start with a very simple J1/J2 Heisenberg spin chain\n",
    "\n",
    "We define a class \"model\" that contains a Hamiltonian and a rule for generating spins according to the MSMS algorithm.\n",
    "\n",
    "We have something to obtain the wavefunction amplitude $\\psi_\\theta(s)$ from the spin configuration $s$ that depends on some amplitude $\\theta$\n",
    "\n",
    "From  $\\psi_\\theta(s)$ for the given spin configuration, we can produce an estimate of the energy of the variational ground state.\n",
    "\n",
    "Then we can perform a stochastic gradient descent based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the RBM class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a class of spin and Hamiltonian, consider a wavefunction object, take takes a spin and returns a number. The variational quantum state is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) = \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\n",
    "\\end{align*}\n",
    "\n",
    "Here the free parameters of the models are $a_i, b_, W_{ij}$ and $h_1, \\dots, h_M$ represents auxilliary spin variables in the network. The internal spins can be explicited traced out to read\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi(S;W) = e^{\\sum_j a_j \\sigma^z_j} \\times \\Pi_{i=1}^M F_i(S)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "F_i(S) = 2\\cosh\\left[ b_i + \\sum_J W_{ij} \\sigma^z_j\\right] =  2\\cosh\\theta_i\n",
    "\\end{align*}\n",
    "\n",
    "The object would be an NN (most basic example includes the Carleo RBM, which actually has an analytical form). $a_j$ is the visible layer with the physical spins, $b_i$ is the hidden layer with an arbitrary layer of hidden spins, while $W_{ij}$ is a weight connecting the physical and hidden spins.\n",
    "\n",
    "I need a function to compute the variational energy. A function to give gradient. And a function to do the gradient descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators and derivatives: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that an operator dcdan be approximated by its local value\n",
    "\n",
    "\\begin{align*}\n",
    "O_{loc}(s) = \\sum_{s, s'}  \\left< s\\middle| O \\middle| s' \\right>\\frac{\\left<s' \\middle| \\Phi_\\theta\\right>}{\\left<s \\middle| \\Phi_\\theta\\right>}\n",
    "\\end{align*}\n",
    "\n",
    "and an operator's expectation value can be reasonably approximated by \n",
    "\n",
    "\\begin{align*}\n",
    "\\left<O \\right> = \\sum_{s} P(s) O_{loc}(s) \\approx \\frac{1}{M} \\sum_{s_i} O_{loc}(s_i)\n",
    "\\end{align*}\n",
    "\n",
    "Now consider the energy minimization. Let $O_p(s) = \\frac{\\partial}{\\partial \\theta_p} \\log \\left<s\\middle|\\Psi_\\theta\\right> = \\left<s\\middle|O_p \\middle| s\\right> $,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E(\\theta)}{\\partial \\theta_p} &= 2 \\Re \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) O^*(\\mathbf{s}) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle O^*(\\mathbf{s}) \\right\\rangle \\right] \\\\\n",
    "&= 2 \\Re \\left[ \\left\\langle (E_{\\text{loc}}(\\mathbf{s}) - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle) O^*(\\mathbf{s}) \\right\\rangle \\right]\n",
    "\\end{align*}\n",
    "\n",
    "To evaluate the derivatives, note that \n",
    "\n",
    "\\begin{align*}\n",
    "O_{a_i} = \\frac{\\partial}{\\partial a_i} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\sigma_i^z \\\\\n",
    "O_{b_j} = \\frac{\\partial}{\\partial b_j} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\tanh(\\theta_j(S)) \\\\\n",
    "O_{W_{ij}} = \\frac{\\partial}{\\partial W_{ij}} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\sigma^z_i\\tanh(\\theta_j(S))\n",
    "\\end{align*}\n",
    "\n",
    "It follows that the gradient is given by (up to proportionality factors)\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E(\\theta)}{\\partial a_i}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\sigma_i^z \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\sigma_i^z \\right\\rangle \\right] \\\\\n",
    "\\frac{\\partial E(\\theta)}{\\partial b_j}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\tanh(\\theta_j(s)) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\tanh(\\theta_j(s)) \\right\\rangle \\right] \\\\\n",
    "\\frac{\\partial E(\\theta)}{\\partial W_{ij}}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\sigma^z_i\\tanh(\\theta_j(s)) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\sigma^z_i\\tanh(\\theta_j(s)) \\right\\rangle \\right]\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, I can use the naive gradient descent. But it tends to have poor convergence because the wavefunction is highly non-linear and correlated. Stchastic reconfiguration is known to have better performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: expectation value of operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-site operators (SzSz only, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <SzSz|ud__|SzSz> is (-0.25+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|dd__|Sz> is (0.25+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.155+0j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <SzSz|ud__|SzSz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[0, 1], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|dd__|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-site operator (Sz makes sense. Unsure if Sx does, but I'll sweep it under the rug for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (0.5+2.661629416864979e-17j) with standard deviation 3.0814879110195774e-33\n",
      "The average expectation  <Sz|d___|Sz> is (-0.5+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.024999999999999984+2.216197069250011e-18j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (-1+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is 0j)\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (1.5150000000000001+0j))\n"
     ]
    }
   ],
   "source": [
    "operator = Operator(model)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        operator += Sz_(i, j, model)\n",
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(operator, batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sx|u___|Sx> is (0.27052722383953354-0.3146306741451852j) with standard deviation 0.0\n",
      "The average expectation  <Sx|d___|Sx> is (0.27052722383953354-0.3146306741451852j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.22609919571493195+0.041158037312519546j))\n"
     ]
    }
   ],
   "source": [
    "#NB: This assumes that the spin is up for probability 2/3 and down for probabilty 1/3\n",
    "#If you set them to be the same the spin expectation is 1/2, which checks out for |up>+|dn>\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sx|u___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sx|d___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(100) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sx_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sy|u___|Sy> is (0.0055333473245139375-0.6675393938788688j) with standard deviation 1.1103585416259206e-16\n",
      "The average expectation  <Sy|d___|Sy> is (0.0055333473245139375-0.6675393938788688j) with standard deviation 1.1103585416259206e-16\n",
      "The average expectation for a 2:1 mixed state is (0.10322278215222992-0.38331483265713673j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sy|u___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sy|d___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "For each iteration:\n",
    "\n",
    "Start with a set of weights.\n",
    "\n",
    "For each weight, initialize the batch of state configurations based on the MCMC. For each state, get the amplitude. The combination gives an estimation of energy. This energy generates an estimation of gradient descent. Change the weight. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average energy is (-2.3176+4.157411223423069e-18j) with standard deviation 0.0683838577443536\n",
      "The spin distributions are [[[0.3604 0.6396]\n",
      "  [0.8058 0.1942]\n",
      "  [0.1602 0.8398]]\n",
      "\n",
      " [[0.153  0.847 ]\n",
      "  [0.5682 0.4318]\n",
      "  [0.353  0.647 ]]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "Ham =  set_h_Hamiltonian(model, h = 4)\n",
    "weight = 5\n",
    "#rbm.set_evaluate_function(rbm.evaluate_function_dummy(weight))\n",
    "\n",
    "N = 5000\n",
    "test = [rbm.expectation_value_batch(Ham, rbm.create_batch(N)) for _ in range(5)]\n",
    "print(f\"The average energy is {np.mean(test)} with standard deviation {np.std(test)}\")\n",
    "\n",
    "batch = rbm.create_batch(N) \n",
    "print(f\"The spin distributions are {np.average(batch, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the initial energy is (1.464+1.8055734712594076e-18j)\n",
      "The spin distributions are [[[0.344 0.656]\n",
      "  [0.155 0.845]\n",
      "  [0.757 0.243]]\n",
      "\n",
      " [[0.654 0.346]\n",
      "  [0.726 0.274]\n",
      "  [0.73  0.27 ]]]\n",
      "the updated energy is (1.432+3.906405268557802e-18j)\n",
      "The spin distributions are [[[0.351 0.649]\n",
      "  [0.15  0.85 ]\n",
      "  [0.739 0.261]]\n",
      "\n",
      " [[0.646 0.354]\n",
      "  [0.746 0.254]\n",
      "  [0.726 0.274]]]\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "Ham =  set_h_Hamiltonian(model, h = 4)\n",
    "#get the current wight and energy\n",
    "a, b, M = rbm.get_weights()\n",
    "batch = rbm.create_batch(N)\n",
    "print(f\"the initial energy is {rbm.expectation_value_batch(Ham, batch)}\")\n",
    "print(f\"The spin distributions are {np.average(batch, axis=0)}\")\n",
    "delta_a, delta_b, delta_M = rbm.get_deltas(Ham, 1)\n",
    "gamma = 0.000000001\n",
    "a -= gamma * delta_a\n",
    "b -= gamma * delta_b\n",
    "M -= gamma * delta_M\n",
    "rbm.set_weights(a, b, M)\n",
    "batch = rbm.create_batch(N)\n",
    "print(f\"the updated energy is {rbm.expectation_value_batch(Ham, batch)}\")\n",
    "print(f\"The spin distributions are {np.average(batch, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating weights at iteration 0\n",
      "Current energy: (1.528-4.827005079602907e-18j)\n",
      "Current Sz: 0.382\n",
      "Updating weights at iteration 1\n",
      "Current energy: (-3.556+1.887957032453548e-17j)\n",
      "Current Sz: -0.889\n",
      "Updating weights at iteration 2\n",
      "Current energy: (-3.8320000000000003+2.2989299589705544e-19j)\n",
      "Current Sz: -0.958\n",
      "Updating weights at iteration 3\n",
      "Current energy: (-5.032+1.637067109346106e-17j)\n",
      "Current Sz: -1.258\n",
      "Updating weights at iteration 4\n",
      "Current energy: (-6.42+2.966886263448077e-17j)\n",
      "Current Sz: -1.605\n",
      "Updating weights at iteration 5\n",
      "Current energy: (-9.268-8.211223243018583e-19j)\n",
      "Current Sz: -2.317\n",
      "Updating weights at iteration 6\n",
      "Current energy: (-10.9+9.088426713206722e-19j)\n",
      "Current Sz: -2.725\n",
      "Updating weights at iteration 7\n",
      "Current energy: (-11.467999999999998-5.862806675688624e-19j)\n",
      "Current Sz: -2.867\n",
      "Updating weights at iteration 8\n",
      "Current energy: (-11.599999999999998+0j)\n",
      "Current Sz: -2.9\n",
      "Updating weights at iteration 9\n",
      "Current energy: (-11.684000000000003-9.694721481546247e-16j)\n",
      "Current Sz: -2.921\n",
      "Updating weights at iteration 10\n",
      "Current energy: (-11.799999999999999+8.627349351915006e-18j)\n",
      "Current Sz: -2.95\n",
      "Updating weights at iteration 11\n",
      "Current energy: (-11.868-1.2452495675689645e-15j)\n",
      "Current Sz: -2.967\n",
      "Updating weights at iteration 12\n",
      "Current energy: (-11.828+1.1861119748783366e-15j)\n",
      "Current Sz: -2.957\n",
      "Updating weights at iteration 13\n",
      "Current energy: (-11.8-1.1232499751759833e-15j)\n",
      "Current Sz: -2.95\n",
      "Updating weights at iteration 14\n",
      "Current energy: (-11.796+0j)\n",
      "Current Sz: -2.949\n",
      "Updating weights at iteration 15\n",
      "Current energy: (-11.868-1.0341204775813387e-15j)\n",
      "Current Sz: -2.967\n",
      "Updating weights at iteration 16\n",
      "Current energy: (-11.924+0j)\n",
      "Current Sz: -2.981\n",
      "Updating weights at iteration 17\n",
      "Current energy: (-11.919999999999998+0j)\n",
      "Current Sz: -2.98\n",
      "Updating weights at iteration 18\n",
      "Current energy: (-11.883999999999999+1.5474613438376567e-15j)\n",
      "Current Sz: -2.971\n",
      "Updating weights at iteration 19\n",
      "Current energy: (-11.468-6.789109087924428e-16j)\n",
      "Current Sz: -2.867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.21232647-0.28516707j,  0.0149094 +0.05305621j,\n",
       "        -0.34748459+0.00143311j, -0.33924761+0.16956976j,\n",
       "        -0.52620625-0.10107772j, -0.33277799-0.11590467j]),\n",
       " array([-0.37662232+0.19905951j, -0.66029705-0.34104079j,\n",
       "         0.14627137+0.30763765j,  0.10840621+0.32196713j,\n",
       "         0.45415959+0.18999317j, -0.574677  -0.38886966j,\n",
       "        -0.10789817+0.28318611j, -0.67960932-0.11285574j,\n",
       "        -0.29974898+0.51879736j]),\n",
       " array([[ 3.07911569e-01-4.89772342e-01j,  3.31794137e-01-1.82413736e-02j,\n",
       "          1.65736259e-01+1.67792739e-01j,  1.41097830e-01+9.09103918e-02j,\n",
       "          1.32205434e-01+3.02874981e-01j, -8.32803472e-02-3.16962748e-01j],\n",
       "        [ 5.73963008e-01+1.44141083e-01j,  2.18187617e-01+1.83149383e-01j,\n",
       "          8.24606650e-01-2.11291611e-01j,  4.73205928e-01-1.68879482e-01j,\n",
       "          2.09718852e-01+3.57666818e-01j,  6.03418060e-02+3.70658839e-01j],\n",
       "        [-3.74543058e-01-4.12346574e-01j, -4.29198412e-01-5.97836289e-01j,\n",
       "         -3.30871598e-01+2.42995202e-01j,  1.75119701e-01-2.68596277e-02j,\n",
       "          1.17565369e-01-2.72516412e-01j, -5.21173383e-02+1.95672911e-01j],\n",
       "        [ 3.62911175e-02-3.21245251e-01j, -1.65292368e-01+3.59747799e-06j,\n",
       "         -3.73940079e-02-3.95305972e-02j, -3.81563681e-02+1.78899868e-01j,\n",
       "         -1.35509694e-01-8.42586002e-02j,  4.20534234e-03-2.03085987e-02j],\n",
       "        [-5.48293581e-01+3.22456521e-01j, -7.78317611e-01-3.75841371e-02j,\n",
       "          2.93718827e-02+1.93316964e-01j, -4.46126648e-01-8.40142908e-02j,\n",
       "         -4.04292396e-01+2.90622844e-02j,  1.05852044e-02-3.83969812e-01j],\n",
       "        [ 6.55611786e-01-3.54958806e-01j,  9.19293895e-02+1.61723242e-01j,\n",
       "          1.67400322e-01+5.70963148e-01j,  4.35934211e-01+4.25750518e-01j,\n",
       "          4.53802395e-01+6.17493725e-02j,  3.15956534e-01+3.75395894e-01j],\n",
       "        [ 3.33543390e-01-9.63396386e-02j,  2.08307199e-01-4.32370238e-01j,\n",
       "          3.45229963e-01-4.72847095e-01j,  7.53981074e-04-5.66179089e-01j,\n",
       "          4.14726946e-01-2.00501072e-01j,  3.17300396e-01-1.75769268e-02j],\n",
       "        [ 3.83448844e-01+2.73327673e-01j,  8.07500586e-01+3.73278448e-01j,\n",
       "          1.14237793e-01+3.72698498e-01j,  4.68026090e-01+4.76240568e-01j,\n",
       "          2.51740299e-01-1.88487270e-01j,  6.85825504e-01+7.98050903e-02j],\n",
       "        [ 3.09291932e-01-5.84234049e-01j,  5.91767532e-01-7.12577952e-02j,\n",
       "          3.38050408e-01-6.14432593e-02j,  5.61344637e-01-7.40323247e-02j,\n",
       "          2.21990107e-01-5.70264787e-01j,  1.27145022e-01+9.92124668e-02j]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "Ham =  set_h_Hamiltonian(model, h = 4)\n",
    "gamma = 10\n",
    "rbm.train(Ham, gamma, N = 1000, n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spin distributions are [[[0.    1.   ]\n",
      "  [0.001 0.999]\n",
      "  [0.004 0.996]]\n",
      "\n",
      " [[0.005 0.995]\n",
      "  [0.008 0.992]\n",
      "  [0.    1.   ]]]\n"
     ]
    }
   ],
   "source": [
    "batch = rbm.create_batch(N)\n",
    "#print(f\"the updated energy is {rbm.expectation_value_batch(Ham, batch)}\")\n",
    "print(f\"The spin distributions are {np.average(batch, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry of the RBM.\n",
    "\n",
    "Consider a translation operator working as $\\sigma_j(k) = T_k \\sigma_j$. An obvious requirement for translation symmetry is that $\\Psi_\\theta(\\sigma) = \\Psi_\\theta(T_s\\sigma)$, and an obvious way to implement this is to just artificially sum over contributions on the output $\\sum_i \\Psi_\\theta(T_{s_i}\\sigma)$, but this won't improve the efficiency of the algorithm.\n",
    "\n",
    "A more tractable wa is to use convolutions. Before we have RBM as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) &= \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, we can rewrite it as below, where $f = 1, \\alpha_s$ is a number of feature maps, and in particular $W_{j}^{(f)} $ has $\\alpha_s \\times N$ elements. Note that because the spins are all summed over all translations this is translation invariant.\n",
    "\n",
    "\\begin{equation}\n",
    "\\Psi_{\\alpha}(\\mathbf{S}; \\mathbf{W}) = \\sum_{h_{i,s}} \\exp \\left[ \\sum_{f}^{a} \\left( a^{(s)} \\sum_{s}^{S} \\sum_{j}^{N} \\tilde{\\sigma}_{j}^{z}(s) + b_{f}^{(s)} h_{f,s} + \\sum_{s}^{S} \\sum_{j}^{N} h_{f,s} W_{j}^{(f)} \\tilde{\\sigma}_{j}^{z}(s) \\right) \\right],\n",
    "\\end{equation}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
