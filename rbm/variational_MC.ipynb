{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import tanh\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import sqrt\n",
    "from model import Model\n",
    "from rbm import RBM\n",
    "from rbm_operator import Operator, Sx_, Sy_, Sz_, SzSz_, set_h_Hamiltonian, set_J1_Hamiltonian, set_J2_Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple attempt to implement a variational quantum state calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the operators are defined as \n",
    "$$S\\cdot S = S_x \\cdot S_x + S_y \\cdot S_y + S_z \\cdot S_z = \\frac{1}{2} (S_+ \\cdot S_- + S_- \\cdot S_+) + S_z \\cdot S_z$$\n",
    "\n",
    "where $S_z = \\frac{\\hbar}{2} \\begin{pmatrix} 1 & 0 \\\\ 0  & -1 \\end{pmatrix}$, $S_+ = \\hbar \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = S_x + S_y$, $S_- = \\hbar \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = S_x - S_y$. A singlet state has energy $-3J/4$ and a triplet state has energy $J/4$\n",
    "\n",
    "As an example, we start with a very simple J1/J2 Heisenberg spin chain\n",
    "\n",
    "We define a class \"model\" that contains a Hamiltonian and a rule for generating spins according to the MSMS algorithm.\n",
    "\n",
    "We have something to obtain the wavefunction amplitude $\\psi_\\theta(s)$ from the spin configuration $s$ that depends on some amplitude $\\theta$\n",
    "\n",
    "From  $\\psi_\\theta(s)$ for the given spin configuration, we can produce an estimate of the energy of the variational ground state.\n",
    "\n",
    "Then we can perform a stochastic gradient descent based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the RBM class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a class of spin and Hamiltonian, consider a wavefunction object, take takes a spin and returns a number. The variational quantum state is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) = \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\n",
    "\\end{align*}\n",
    "\n",
    "Here the free parameters of the models are $a_i, b_, W_{ij}$ and $h_1, \\dots, h_M$ represents auxilliary spin variables in the network. The internal spins can be explicited traced out to read\n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi(S;W) = e^{\\sum_j a_j \\sigma^z_j} \\times \\Pi_{i=1}^M F_i(S)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "F_i(S) = 2\\cosh\\left[ b_i + \\sum_J W_{ij} \\sigma^z_j\\right] =  2\\cosh\\theta_i\n",
    "\\end{align*}\n",
    "\n",
    "The object would be an NN (most basic example includes the Carleo RBM, which actually has an analytical form). $a_j$ is the visible layer with the physical spins, $b_i$ is the hidden layer with an arbitrary layer of hidden spins, while $W_{ij}$ is a weight connecting the physical and hidden spins.\n",
    "\n",
    "I need a function to compute the variational energy. A function to give gradient. And a function to do the gradient descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators and derivatives: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that an operator dcdan be approximated by its local value\n",
    "\n",
    "\\begin{align*}\n",
    "O_{loc}(s) = \\sum_{s, s'}  \\left< s\\middle| O \\middle| s' \\right>\\frac{\\left<s' \\middle| \\Phi_\\theta\\right>}{\\left<s \\middle| \\Phi_\\theta\\right>}\n",
    "\\end{align*}\n",
    "\n",
    "and an operator's expectation value can be reasonably approximated by \n",
    "\n",
    "\\begin{align*}\n",
    "\\left<O \\right> = \\sum_{s} P(s) O_{loc}(s) \\approx \\frac{1}{M} \\sum_{s_i} O_{loc}(s_i)\n",
    "\\end{align*}\n",
    "\n",
    "Now consider the energy minimization. Let $O_p(s) = \\frac{\\partial}{\\partial \\theta_p} \\log \\left<s\\middle|\\Psi_\\theta\\right> = \\left<s\\middle|O_p \\middle| s\\right> $,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E(\\theta)}{\\partial \\theta_p} &= 2 \\Re \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) O^*(\\mathbf{s}) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle O^*(\\mathbf{s}) \\right\\rangle \\right] \\\\\n",
    "&= 2 \\Re \\left[ \\left\\langle (E_{\\text{loc}}(\\mathbf{s}) - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle) O^*(\\mathbf{s}) \\right\\rangle \\right]\n",
    "\\end{align*}\n",
    "\n",
    "To evaluate the derivatives, note that \n",
    "\n",
    "\\begin{align*}\n",
    "O_{a_i} = \\frac{\\partial}{\\partial a_i} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\sigma_i^z \\\\\n",
    "O_{b_j} = \\frac{\\partial}{\\partial b_j} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\tanh(\\theta_j(S)) \\\\\n",
    "O_{W_{ij}} = \\frac{\\partial}{\\partial W_{ij}} \\log \\left<s\\middle|\\Psi_\\theta\\right> &= \\sigma^z_i\\tanh(\\theta_j(S))\n",
    "\\end{align*}\n",
    "\n",
    "It follows that the gradient is given by (up to proportionality factors)\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E(\\theta)}{\\partial a_i}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\sigma_i^z \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\sigma_i^z \\right\\rangle \\right] \\\\\n",
    "\\frac{\\partial E(\\theta)}{\\partial b_j}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\tanh(\\theta_j(s)) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\tanh(\\theta_j(s)) \\right\\rangle \\right] \\\\\n",
    "\\frac{\\partial E(\\theta)}{\\partial W_{ij}}  &= \\left[ \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\sigma^z_i\\tanh(\\theta_j(s)) \\right\\rangle - \\left\\langle E_{\\text{loc}}(\\mathbf{s}) \\right\\rangle \\left\\langle \\sigma^z_i\\tanh(\\theta_j(s)) \\right\\rangle \\right]\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, I can use the naive gradient descent. But it tends to have poor convergence because the wavefunction is highly non-linear and correlated. Stchastic reconfiguration is known to have better performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: expectation value of operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-site operators (SzSz only, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <SzSz|ud__|SzSz> is (-0.25+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|dd__|Sz> is (0.25+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.155+0j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <SzSz|ud__|SzSz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), np.array([[[0, 1], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|dd__|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(SzSz_(0,0,0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-site operator (Sz makes sense. Unsure if Sx does, but I'll sweep it under the rug for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (0.5+2.661629416864979e-17j) with standard deviation 3.0814879110195774e-33\n",
      "The average expectation  <Sz|d___|Sz> is (-0.5+0j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.024999999999999984+2.216197069250011e-18j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is (-1+0j) with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is 0j)\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sz_(1,0,model)+Sz_(0,1,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sz|u___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation  <Sz|d___|Sz> is 0j with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (1.5150000000000001+0j))\n"
     ]
    }
   ],
   "source": [
    "operator = Operator(model)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        operator += Sz_(i, j, model)\n",
    "model = Model(2,2)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sz|u___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(operator, np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sz|d___|Sz> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(operator, batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sx|u___|Sx> is (0.27052722383953354-0.3146306741451852j) with standard deviation 0.0\n",
      "The average expectation  <Sx|d___|Sx> is (0.27052722383953354-0.3146306741451852j) with standard deviation 0.0\n",
      "The average expectation for a 2:1 mixed state is (0.22609919571493195+0.041158037312519546j))\n"
     ]
    }
   ],
   "source": [
    "#NB: This assumes that the spin is up for probability 2/3 and down for probabilty 1/3\n",
    "#If you set them to be the same the spin expectation is 1/2, which checks out for |up>+|dn>\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sx|u___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sx_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sx|d___|Sx> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(100) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sx_(0,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average expectation <Sy|u___|Sy> is (0.0055333473245139375-0.6675393938788688j) with standard deviation 1.1103585416259206e-16\n",
      "The average expectation  <Sy|d___|Sy> is (0.0055333473245139375-0.6675393938788688j) with standard deviation 1.1103585416259206e-16\n",
      "The average expectation for a 2:1 mixed state is (0.10322278215222992-0.38331483265713673j))\n"
     ]
    }
   ],
   "source": [
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation <Sy|u___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), np.array([[[1, 0], [0, 1], [1, 0]], [[0, 1], [1, 0], [1,0]]])) for _ in range(40)]\n",
    "print(f\"The average expectation  <Sy|d___|Sy> is {np.mean(average_expectations)} with standard deviation {np.std(average_expectations)}\")\n",
    "rbm = RBM(model)\n",
    "batch = rbm.create_batch(200) #This uses evaluate_dummy, which gives 2/3 for spin up and 1/3 for spin down \n",
    "average_expectations = [rbm.expectation_value(Sy_(1,0,model), batch[i]) for i in range(len(batch))]\n",
    "print(f\"The average expectation for a 2:1 mixed state is {np.mean(average_expectations)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "For each iteration:\n",
    "\n",
    "Start with a set of weights.\n",
    "\n",
    "For each weight, initialize the batch of state configurations based on the MCMC. For each state, get the amplitude. The combination gives an estimation of energy. This energy generates an estimation of gradient descent. Change the weight. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure J hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#rbm.set_evaluate_function(rbm.evaluate_function_dummy(weight))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m----> 8\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpectation_value_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe average energy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with standard deviation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m batch \u001b[38;5;241m=\u001b[39m rbm\u001b[38;5;241m.\u001b[39mcreate_batch(N) \n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#rbm.set_evaluate_function(rbm.evaluate_function_dummy(weight))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m----> 8\u001b[0m test \u001b[38;5;241m=\u001b[39m [rbm\u001b[38;5;241m.\u001b[39mexpectation_value_batch(Ham, \u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe average energy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with standard deviation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m batch \u001b[38;5;241m=\u001b[39m rbm\u001b[38;5;241m.\u001b[39mcreate_batch(N) \n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:88\u001b[0m, in \u001b[0;36mRBM.create_batch\u001b[0;34m(self, N, burn_in, skip)\u001b[0m\n\u001b[1;32m     86\u001b[0m result_array[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m current_spins\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N\u001b[38;5;241m*\u001b[39mskip):\n\u001b[0;32m---> 88\u001b[0m     current_spins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetropolis_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_spins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m skip \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     90\u001b[0m         result_array[i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mskip] \u001b[38;5;241m=\u001b[39m current_spins\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:71\u001b[0m, in \u001b[0;36mRBM.metropolis_step\u001b[0;34m(self, spin)\u001b[0m\n\u001b[1;32m     69\u001b[0m spin2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mflip_random_spin(spin)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#print(self.evaluate(spin2),self.evaluate(spin))\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_function(spin2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspin\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m p:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spin2\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:61\u001b[0m, in \u001b[0;36mRBM.evaluate\u001b[0;34m(self, spin)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mEvaluate the wavefunction for a given spin configuration\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spin\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL2, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid spin shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspin\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 61\u001b[0m projected_spin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_spin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#print(self.M, projected_spin, np.prod(2 * np.cosh(self.b + np.dot(self.M, projected_spin))))\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma, projected_spin)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcosh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM, projected_spin)))\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/model.py:21\u001b[0m, in \u001b[0;36mModel.project_spin\u001b[0;34m(self, spin)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproject_spin\u001b[39m(\u001b[38;5;28mself\u001b[39m, spin):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Helper function. Given the spins (L1, L2, 2), project them down to a shape (L1*L2)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    In lieu of the one-hot spin representation, each spin entry [1,0] and [0,1] is mapped to 1/2 and -1/2 respectively\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spin[:,:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "Ham =  set_J1_Hamiltonian(model, J = 4)\n",
    "weight = 5\n",
    "#rbm.set_evaluate_function(rbm.evaluate_function_dummy(weight))\n",
    "\n",
    "N = 5000\n",
    "test = [rbm.expectation_value_batch(Ham, rbm.create_batch(N)) for _ in range(5)]\n",
    "print(f\"The average energy is {np.mean(test)} with standard deviation {np.std(test)}\")\n",
    "\n",
    "batch = rbm.create_batch(N) \n",
    "print(f\"The spin distributions are {np.average(batch, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating weights at iteration 0\n",
      "[[17.71      +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j         24.36      +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j         24.84      +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " ...\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.25737829+0.58039791j  0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          1.76556573+0.39438617j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "  -0.37316803+0.66353299j]]\n",
      "Current energy: (6.842705946790314+0.3722400769108576j)\n",
      "Updating weights at iteration 1\n",
      "[[ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          2.619     +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.891     +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " ...\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ... -0.14030986+0.19826443j  0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j         -0.14030986+0.19826443j\n",
      "   0.        +0.j        ]\n",
      " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   6.43129809+1.50534799j]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m Ham \u001b[38;5;241m=\u001b[39m  set_J1_Hamiltonian(model, J \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      5\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:225\u001b[0m, in \u001b[0;36mRBM.train\u001b[0;34m(self, Ham, gamma, operator, N, n_iter, verbose)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, Ham, gamma, operator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    227\u001b[0m             batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_batch(N)\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:214\u001b[0m, in \u001b[0;36mRBM.update_weights\u001b[0;34m(self, Ham, gamma, p, N, verbose)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating weights at iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m delta_as, delta_bs, delta_Ws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_deltas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m gamma \u001b[38;5;241m*\u001b[39m delta_as\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m gamma \u001b[38;5;241m*\u001b[39m delta_bs\n",
      "File \u001b[0;32m~/Documents/Jupyter/machine_learning/rbm/rbm.py:197\u001b[0m, in \u001b[0;36mRBM.get_deltas\u001b[0;34m(self, Ham, p, N)\u001b[0m\n\u001b[1;32m    195\u001b[0m Skk_reg \u001b[38;5;241m=\u001b[39m Skk \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay(p) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiagonal(Skk)) \u001b[38;5;66;03m#np.eye(Skk.shape[0])\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay(p) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiagonal(Skk)))\n\u001b[0;32m--> 197\u001b[0m Skk_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSkk_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m delta_as \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Es[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m sigmas, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Es) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sigmas, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    200\u001b[0m delta_bs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Es[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m tanhs, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Es) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(tanhs, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "model = Model(2,3)\n",
    "rbm = RBM(model)\n",
    "Ham =  set_J1_Hamiltonian(model, J = 4)\n",
    "gamma = 1\n",
    "rbm.train(Ham, gamma, N = 1000, n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m Skk \u001b[38;5;241m=\u001b[39m Oj_Ok \u001b[38;5;241m-\u001b[39m mean_Oj_Ok\n\u001b[1;32m     20\u001b[0m Skk_reg \u001b[38;5;241m=\u001b[39m Skk \u001b[38;5;241m+\u001b[39m rbm\u001b[38;5;241m.\u001b[39mdecay(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiagonal(Skk)) \u001b[38;5;66;03m#np.eye(Skk.shape[0])\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m Skk_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSkk_reg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "batch = rbm.create_batch(N)\n",
    "# Implement a Hamiltonian\n",
    "Es = np.array([rbm.expectation_value(Ham, spin) for spin in batch]) \n",
    "tanhs =  np.array([tanh(rbm.theta(spin)) for spin in batch])\n",
    "sigmas = np.array([rbm.model.project_spin(spin) for spin in batch])\n",
    "\n",
    "Oais =  sigmas\n",
    "Objs =  tanhs\n",
    "Owijs = tanhs[:, :, np.newaxis] * sigmas[:, np.newaxis, :]\n",
    "# Flatten W and concatenate a, b, W\n",
    "O = np.concatenate([Oais, Objs, Owijs.reshape(N, -1)], axis=1)\n",
    "mean_O = np.mean(O, axis=0)\n",
    "# Compute <Oj Ok>\n",
    "Oj_Ok = np.einsum('ij,ik->jk', O, O) / N\n",
    "# Compute <Oj><Ok>\n",
    "mean_Oj_Ok = np.outer(mean_O, mean_O)\n",
    "# Correlation matrix\n",
    "Skk = Oj_Ok - mean_Oj_Ok\n",
    "\n",
    "Skk_reg = Skk + rbm.decay(1) * np.diag(np.diagonal(Skk)) #np.eye(Skk.shape[0])\n",
    "Skk_inv = np.linalg.inv(Skk_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero entries are located at: []\n"
     ]
    }
   ],
   "source": [
    "zero_indices = np.where(Oj_Ok == 0)\n",
    "\n",
    "# Convert the indices to a list of tuples for easier interpretation\n",
    "zero_locations = list(zip(zero_indices[0], zero_indices[1]))\n",
    "\n",
    "print(\"Zero entries are located at:\", zero_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f331c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(np.abs(Skk_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry of the RBM.\n",
    "\n",
    "Consider a translation operator working as $\\sigma_j(k) = T_k \\sigma_j$. An obvious requirement for translation symmetry is that $\\Psi_\\theta(\\sigma) = \\Psi_\\theta(T_s\\sigma)$, and an obvious way to implement this is to just artificially sum over contributions on the output $\\sum_i \\Psi_\\theta(T_{s_i}\\sigma)$, but this won't improve the efficiency of the algorithm.\n",
    "\n",
    "A more tractable wa is to use convolutions. Before we have RBM as \n",
    "\n",
    "\\begin{align*}\n",
    "\\Psi_M(S;W) &= \\sum_{h_i} e^{\\sum_j a_j \\sigma^z_j + \\sum_i b_i h_i + \\sum_{ij} W_{ij} h_i \\sigma^{z}_j}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, we can rewrite it as below, where $f = 1, \\alpha_s$ is a number of feature maps, and in particular $W_{j}^{(f)} $ has $\\alpha_s \\times N$ elements. Note that because the spins are all summed over all translations this is translation invariant.\n",
    "\n",
    "\\begin{equation}\n",
    "\\Psi_{\\alpha}(\\mathbf{S}; \\mathbf{W}) = \\sum_{h_{i,s}} \\exp \\left[ \\sum_{f}^{a} \\left( a^{(s)} \\sum_{s}^{S} \\sum_{j}^{N} \\tilde{\\sigma}_{j}^{z}(s) + b_{f}^{(s)} h_{f,s} + \\sum_{s}^{S} \\sum_{j}^{N} h_{f,s} W_{j}^{(f)} \\tilde{\\sigma}_{j}^{z}(s) \\right) \\right],\n",
    "\\end{equation}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
